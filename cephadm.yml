# Copyright (C) 2020 Red Hat, Inc.
#
# This program is free software: you can redistribute it and/or modify it under
# the terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# This program is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
# PARTICULAR PURPOSE.  See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along with
# this program.  If not, see <https://www.gnu.org/licenses/>.---

- name: import configurations
  import_playbook: settings.yml

- name: preconfigure linodes
  import_playbook: pre-config.yml

- hosts: mons mgrs osds mdss grafana-servers clients
  become: yes
  tasks:
  - name: setup mon-000 ssh key
    delegate_to: mon-000
    run_once: true
    community.crypto.openssh_keypair:
      path: /root/.ssh/id_ed25519
      type: ed25519
      comment: mon-000
    register: cephadm_key

  - name: register cephadm.id-ed25519 with hosts
    lineinfile:
      path: /root/.ssh/authorized_keys
      line: "{{ cephadm_key.public_key }}"

- hosts: mons
  become: yes
  tasks:
  - name: read cephadm private key from mon-000
    slurp:
      src: /root/.ssh/id_ed25519
    delegate_to: mon-000
    run_once: true
    register: cephadm_priv_key_b64

  - name: read cephadm public key from mon-000
    slurp:
      src: /root/.ssh/id_ed25519.pub
    delegate_to: mon-000
    run_once: true
    register: cephadm_pub_key_b64

  - name: distribute cephadm private key to mons
    copy:
      dest: /root/.ssh/id_ed25519
      content: "{{ cephadm_priv_key_b64.content | b64decode }}"
      owner: root
      group: root
      mode: '0600'
    when: inventory_hostname != 'mon-000'

  - name: distribute cephadm public key to mons
    copy:
      dest: /root/.ssh/id_ed25519.pub
      content: "{{ cephadm_pub_key_b64.content | b64decode }}"
      owner: root
      group: root
      mode: '0644'
    when: inventory_hostname != 'mon-000'

  - name: gather host keys from all nodes
    shell: "ssh-keyscan -H {{ hostvars[item].ansible_ssh_host }} {{ item }}"
    loop: "{{ groups['mons'] + groups['mgrs'] + groups['osds'] + groups['mdss'] + groups['clients'] | unique }}"
    register: host_keys
    changed_when: false

  - name: update known_hosts on mons
    known_hosts:
      name: "{{ item.item }}"
      key: "{{ item.stdout }}"
      path: /root/.ssh/known_hosts
      state: present
    loop: "{{ host_keys.results }}"
    when: item.stdout is defined and item.stdout != ""

- hosts: mons mgrs osds mdss clients
  become: yes
  tasks:
  - name: fetch cephadm
    become: no
    delegate_to: localhost
    run_once: true
    ansible.builtin.get_url:
      url: "https://download.ceph.com/rpm-{{ RELEASE }}/el9/noarch/cephadm"
      dest: "/tmp/cephadm-{{ RELEASE }}"
      mode: "0755"
      force: yes

  - name: distribute cephadm
    copy:
      dest: /root/cephadm
      group: root
      mode: 0755
      owner: root
      src: "/tmp/cephadm-{{ RELEASE }}"
      remote_src: false

  - name: "add {{ RELEASE }} repos"
    shell: "/root/cephadm add-repo {{ CEPHADM_REPO }}"

  - name: "install {{ RELEASE }}"
    shell: "/root/cephadm install ceph-common"

- hosts: mon-000
  become: yes
  tasks:
  - name: reset cluster.spec (avoid mixed/invalid YAML from previous runs)
    file:
      path: /root/cluster.spec
      state: absent

  - name: read cluster.json (base)
    set_fact:
      cluster_cfg: "{{ lookup('file', 'cluster.json') | from_json }}"

  - name: locate osd node config (group=osds)
    set_fact:
      osd_node_cfg: >-
        {{
          (cluster_cfg.nodes | selectattr('group', 'defined') | selectattr('group', 'equalto', 'osds') | list + [none]) | first
          or
          (cluster_cfg.nodes | selectattr('groups', 'defined') | selectattr('groups', 'contains', 'osds') | list + [none]) | first
        }}

  - name: validate cluster.json has an osds node entry
    fail:
      msg: >-
        cluster.json is missing a nodes[] entry with group/groups containing "osds".
        Add an OSD node definition that includes "osd_devices_by_host".
    when: osd_node_cfg is none

  - name: read cluster.json (for per-host OSD devices)
    set_fact:
      osd_devices_by_host: "{{ (osd_node_cfg | default({}, true)).get('osd_devices_by_host', {}) }}"
      osd_hosts: >-
        {%- set out = [] -%}
        {%- for node in cluster_cfg.nodes -%}
          {%- set gs = node.get('groups', []) -%}
          {%- if (gs | length) == 0 and (node.get('group') is not none) -%}
            {%- set gs = [node.get('group')] -%}
          {%- endif -%}
          {%- if 'osds' in gs -%}
            {%- for i in range((node.get('count') | int)) -%}
              {%- set _ = out.append('%s-%03d' % (node.get('prefix'), i)) -%}
            {%- endfor -%}
          {%- endif -%}
        {%- endfor -%}
        {{ out }}

  - name: validate every OSD host has a device list in cluster.json
    fail:
      msg: >-
        Missing OSD device list for host '{{ item }}'.
        Add it under nodes[].osd_devices_by_host in cluster.json, e.g.:
        "osd_devices_by_host": { "{{ item }}": ["/dev/sdX"] }
    loop: "{{ osd_hosts }}"
    when: (osd_devices_by_host.get(item, []) | length) == 0

  - name: write cephadm spec (single clean YAML stream)
    copy:
      dest: /root/cluster.spec
      owner: root
      group: root
      mode: "0644"
      content: |
        {# Build host_list and labels_by_host from cluster.json nodes[] #}
        {% set host_list = [] %}
        {% set labels_by_host = {} %}

        {% for node in cluster_cfg.nodes %}
        {%   set gs = node.get('groups', []) %}
        {%   if (gs | length) == 0 and (node.get('group') is not none) %}
        {%     set gs = [node.get('group')] %}
        {%   endif %}
        {%   for i in range((node.get('count') | int)) %}
        {%     set h = '%s-%03d' % (node.get('prefix'), i) %}
        {%     if h not in host_list %}
        {%       set _ = host_list.append(h) %}
        {%     endif %}
        {%     if h not in labels_by_host %}
        {%       set _ = labels_by_host.update({h: []}) %}
        {%     endif %}
        {%     for g in gs %}
        {%       if g and g not in labels_by_host[h] %}
        {%         set _ = labels_by_host[h].append(g) %}
        {%       endif %}
        {%     endfor %}
        {%   endfor %}
        {% endfor %}

        {# Host specs #}
        {% for h in host_list %}
        {% if not loop.first %}---
        {% endif %}
        service_type: host
        hostname: {{ h }}
        addr: {{ hostvars[h]['ansible_ssh_host'] }}
        labels:
        {% for lab in labels_by_host.get(h, []) %}
          - {{ lab }}
        {% endfor %}
        {% if 'mons' in labels_by_host.get(h, []) %}
          - _admin
        {% endif %}
        {% endfor %}

        ---
        service_type: mon
        placement:
          label: mons

        ---
        service_type: mgr
        placement:
          label: mgrs

        {# Per-host OSD service specs #}
        {% for h in osd_hosts %}
        ---
        service_id: {{ h }}
        service_type: osd
        placement:
          hosts:
            - {{ h }}
        data_devices:
          paths:
        {% for dev in osd_devices_by_host.get(h, []) %}
            - {{ dev }}
        {% endfor %}
        {% endfor %}


  - name: check ceph already bootstrapped
    stat:
      path: /etc/ceph/ceph.conf
    register: ceph_installed

  - name: "cephadm bootstrap"
    shell: "/root/cephadm --image {{ CEPH_IMAGE }} bootstrap --mon-ip {{ monitor_address }} --ssh-private-key /root/.ssh/id_ed25519 --ssh-public-key /root/.ssh/id_ed25519.pub --apply-spec /root/cluster.spec"
    when: not ceph_installed.stat.exists

  - name: config public network
    shell: ceph config set global public_network 10.251.0.0/16

  - name: config cluster_network
    shell: ceph config set global cluster_network 10.251.0.0/16

  - name: log to files
    shell: ceph config set global log_to_file true

  - name: log cluster to file
    shell: ceph config set global mon_cluster_log_to_file true

  - name: disable stderr logging
    shell: ceph config set global log_to_stderr false

  - name: disable stderr logging of cluster log
    shell: ceph config set global mon_cluster_log_to_stderr false

- hosts: clients
  become: yes
  tasks:
  - name: "add {{ RELEASE }} repos"
    shell: "/root/cephadm add-repo {{ CEPHADM_REPO }}"

  - name: "install {{ RELEASE }}"
    shell: "/root/cephadm install ceph-common ceph-fuse"

  - name: generate min config
    shell: ceph config generate-minimal-conf
    delegate_to: mon-000
    register: minimal_config
    run_once: true

  - name: setup config
    copy:
      # yay ansible bug: https://github.com/ansible/ansible/issues/6077
      content: "{{ minimal_config.stdout }}\n"
      dest: /etc/ceph/ceph.conf
      owner: root
      group: root
      mode: 0644
